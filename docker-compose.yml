services:
  # ---------------------------------------------------------------------------
  # ZOOKEEPER (necessário para Kafka)
  # ---------------------------------------------------------------------------
  zookeeper:
    image: bitnami/zookeeper:3.8
    container_name: zookeeper
    environment:
      - ZOO_ENABLE_AUTH=no
      - ALLOW_ANONYMOUS_LOGIN=yes
    ports:
      - "2181:2181"
    networks:
      - my-net

  # ---------------------------------------------------------------------------
  # KAFKA
  # ---------------------------------------------------------------------------
  kafka:
    image: bitnami/kafka:3.5
    container_name: kafka
    depends_on:
      - zookeeper
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - ALLOW_PLAINTEXT_LISTENER=yes
    ports:
      - "9092:9092"
    networks:
      - my-net

  # ---------------------------------------------------------------------------
  # POSTGRES
  # ---------------------------------------------------------------------------
  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"
    networks:
      - my-net
    volumes:
      - pgdata:/var/lib/postgresql/data
    command: [ "postgres", "-c", "wal_level=logical" ]

  # ---------------------------------------------------------------------------
  # MONGODB
  # ---------------------------------------------------------------------------
  mongo:
    image: mongo:6
    container_name: mongo
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: admin
    ports:
      - "27017:27017"
    networks:
      - my-net
    volumes:
      - mongodata:/data/db

  # ---------------------------------------------------------------------------
  # DEBEZIUM CONNECT (para capturar mudanças em Postgres/Mongo e enviar para Kafka)
  # ---------------------------------------------------------------------------
  debezium:
    image: debezium/connect:2.3
    container_name: debezium
    depends_on:
      - kafka
      - postgres
      - mongo
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: debezium_configs
      OFFSET_STORAGE_TOPIC: debezium_offsets
      STATUS_STORAGE_TOPIC: debezium_statuses
      KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      # Exemplo: conectar com Postgres e Mongo
      # Para cada conector será preciso adicionar .json de configuração na pasta "connectors" ou via REST
    ports:
      - "8083:8083"
    networks:
      - my-net
    volumes:
      - ./connectors:/kafka/connectors

  # ---------------------------------------------------------------------------
  # SPARK MASTER
  # ---------------------------------------------------------------------------
  spark-master:
    image: bitnami/spark:3.5
    container_name: spark-master
    environment:
      - SPARK_MODE=master
    volumes:
      - ./spark-apps:/opt/spark-apps
    ports:
      - "7077:7077"  # Spark Master
      - "8080:8080"  # Spark Web UI
    networks:
      - my-net

  # ---------------------------------------------------------------------------
  # SPARK WORKER
  # ---------------------------------------------------------------------------
  spark-worker:
    image: bitnami/spark:3.5
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./spark-apps:/opt/spark-apps
    ports:
      - "8081:8081"
    networks:
      - my-net

  # ---------------------------------------------------------------------------
  # AIRFLOW
  # ---------------------------------------------------------------------------
  airflow:
    # Caso prefira uma imagem já pronta, pode usar apache/airflow:2.6 ou similar
    build:
      context: ./airflow
      dockerfile: Dockerfile
    container_name: airflow
    depends_on:
      - spark-master
      - spark-worker
      - kafka
      - postgres
      - mongo
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__FERNET_KEY: -gB_1UQVIMX_AvRiY6N7_5InX5J_YT0VkqRF5D89T64=
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: False
      AIRFLOW__CORE__LOAD_EXAMPLES: False
      AIRFLOW__WEBSERVER__ENABLE_PROXY_FIX: True
      AIRFLOW_UID: 50000
      AIRFLOW_GID: 50000
    volumes:
      - ./airflow/dags:/opt/airflow/dags
    ports:
      - "8089:8080"
    networks:
      - my-net
    command: >
      bash -c "
        airflow db init &&
        airflow users create --username admin --firstname air --lastname flow --role Admin --email admin@example.org --password admin &&
        airflow webserver &&
        sleep 10 &&
        airflow scheduler
      "

networks:
  my-net:
    driver: bridge

volumes:
  pgdata:
  mongodata:
